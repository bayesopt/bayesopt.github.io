---
permalink: past/2016.html
weight: -1
---

BayesOpt2015<br>Bayesian Optimization: Black-box Optimization and Beyond
------------------

Bayesian optimization has emerged as an exciting subfield of machine learning that is concerned with the global optimization of expensive, noisy, black-box functions using probabilistic methods. Systems implementing Bayesian optimization techniques have been successfully used to solve difficult problems in a diverse set of applications. Many recent advances in the methodologies and theory underlying Bayesian optimization have extended the framework to new applications and provided greater insights into the behaviour of these algorithms. Bayesian optimization is now increasingly being used in industrial settings, providing new and interesting challenges that require new algorithms and theoretical insights.

Classically, Bayesian optimization has been used purely for expensive single-objective black-box optimization. However, with the increased complexity of tasks and applications, this paradigm is proving to be too restricted. Hence, this year’s theme for the workshop will be “black-box optimization and beyond”. Among the recent trends that push beyond BO we can briefly enumerate:
- Adapting BO to not-so-expensive evaluations.
- “Open the black-box” and move away from viewing the model as a way of simply fitting a response surface, and towards modelling for the purpose of discovering and understanding the underlying process. For instance, this so-called grey-box modelling approach could be valuable in robotic applications for optimizing the controller, while simultaneously providing insight into the mechanical properties of the robotic system. 
- “Meta-learning”, where a higher level of learning is used on top of BO in order to control the optimization process and make it more efficient. Examples of such meta-learning include learning curve prediction, Freeze-thaw Bayesian optimization, online batch selection, multi-task and multi-fidelity learning.
- Multi-objective optimization where not a single objective, but multiple conflicting objectives are considered (e.g., prediction accuracy vs training time).

The target audience for this workshop consists of both industrial and academic practitioners of Bayesian optimization as well as researchers working on theoretical and practical advances in probabilistic optimization. We expect that this pairing of theoretical and applied knowledge will lead to an interesting exchange of ideas and stimulate an open discussion about the long term goals and challenges of the Bayesian optimization community.

A further goal of this workshop is to encourage collaboration between the diverse set of researchers involved in Bayesian optimization. This includes not only interchange between industrial and academic researchers, but also between the many different subfields of machine learning which make use of Bayesian optimization or its components. We are also reaching out to the wider optimization and engineering communities for involvement.


Invited speakers and panelists
------------------

- [Joshua Knowles](http://www.cs.bham.ac.uk/~jdk/) (University of Birmingham)
- Alex Wiltschko
- [Marc Toussaint](www.marc-toussaint.net) (University of Stuttgart)
- [Roman Garnett](http://www.cse.wustl.edu/~garnett/) (Washington University in St. Louis)
- [Katharina Eggensperger](http://aad.informatik.uni-freiburg.de/people/eggensperger/index.html) (University of Freiburg)


Organizers
------------------

- [Roberto Calandra](http://www.robertocalandra.com) (UC Berkeley)
- [Bobak Shahriari](http://cs.ubc.ca/~bshahr/) (University of British Columbia)
- [Javier Gonzalez](http://javiergonzalezh.github.io/) (Amazon)
- [Frank Hutter](http://www2.informatik.uni-freiburg.de/~hutter/) (University of Freiburg)
- [Ryan P. Adams](http://www.seas.harvard.edu/directory/rpa) (Harvard University)


Program Committee
------------------

We would like to thank our program committee for their great help in reviewing submissions: 

Archambeau Cedric, Emile Contal, Daniel Hernandez-Lobato, David Duvenaud, Katharina Eggensperger, Favour Nyikosa, Matthias Feurer, Roman Garnett, Ian Dewancker, John-Alexander Assael, Rodolphe Jenatton, Jan H Metzen, Jose Miguel Hernandez-Lobato, James Wilson, Aaron Klein, Kevin Swersky, Marc Deisenroth, Mike Mccourt, Mickaël Binois, Matt Hoffman, Philipp Hennig, Ruben Martinez-Cantin, Stefan Falkner, Paul Supratik, Takayuki Osa, Filipe Veiga, Zhenwen Dai, Zi Wang, Ziyu Wang.


Accepted papers
------------------

Below are the papers accepted for the 2016 workshop. For papers accepted at
previous workshops [look here](/past/).

- hyperSPACE: Automated Optimization of Complex Processing Pipelines for pySPACE<br>
  Torben Hansing, Mario Michael Krell, Frank Kirchner
  [(pdf)](/papers/2016/Hansing.pdf)
- Predictive Entropy Search for Multi-objective Bayesian Optimization with Constraints<br>
  Eduardo Garrido-Merchán, Daniel Hernandez-Lobato
  [(pdf)](/papers/2016/Garrido.pdf)			
- Multi-objective Optimization with Unbounded Solution Sets<br>
  Oswin Krause, Tobias Glasmachers, Christian Igel
  [(pdf)](/papers/2016/Krause.pdf)
- Quantifying mismatch in Bayesian optimization<br>
  Eric Schulz, Maarten Speekenbrink, Jose Miguel Hernandez-Lobato, Zoubin  Ghahramani, Samuel Gershman
  [(pdf)](/papers/2016/Schulz.pdf)
- Preemptive Termination of Suggestions during Sequential Kriging Optimization of a Brain Activity  Reconstruction Simulation<br>
  Mike Mccourt, Ian Dewancker, Salvatore Ganci
  [(pdf)](/papers/2016/Mccourt.pdf)
- Advancing Bayesian Optimization: The Mixed-Global-Local (MGL) Kernel and Length-Scale Cool Down<br>
  Kim Wabersich, Marc Toussaint
  [(pdf)](/papers/2016/Wabersich.pdf) [(arxiv)](https://arxiv.org/abs/1612.03117)
- Hypervolume-based Multi-objective Bayesian Optimization with Student-t Processes<br>
  Joachim Van der Herten, Ivo Couckuyt, Tom Dhaene
  [(pdf)](/papers/2016/Herten.pdf)		
- Factored Contextual Policy Search with Bayesian Optimization<br>
  Peter Karkus, Andras Kupcsik, David Hsu, Wee Sun Lee
  [(pdf)](/papers/2016/Karkus.pdf)
- Infinite dimensions optimistic optimisation with applications on physical systems<br>
  Muhammad Kasim, Peter Norreys,
  [(pdf)](/papers/2016/Kasim.pdf)
- A Physically-grounded and Data-efficient Approach to Motion Prediction using Black-box Optimization<br>
  Shaojun Zhu, Abdeslam Boularias
  [(pdf)](/papers/2016/Zhu.pdf)		
- A Simple Recursive Algorithm for calculating Expected Hypervolume Improvement<br>
  Alistair Shilton, Santu Rana, Sunil Gupta, Svetha Venkatesh
  [(pdf)](/papers/2016/Shilton.pdf)			
- High Dimensional Bayesian Optimization with Elastic Gaussian Process<br>
  Cheng Li, Santu Rana, Sunil Gupta, Vu Nguyen, Svetha Venkatesh
  [(pdf)](/papers/2016/Li.pdf)
- Hybrid Repeat/Multi-point Sampling for Highly Volatile Objective Functions<br>
  Brett Israelsen, Nisar Ahmed
  [(pdf)](/papers/2016/Israelsen.pdf) [(arxiv)](https://arxiv.org/abs/1612.03981)	
- Bayesian Optimisation for solving Continuous State-Action-Observation POMDPs<br>
	Philippe Morere, Roman Marchant, Fabio Ramos
  [(pdf)](/papers/2016/Morere.pdf)		
- Multiple Recommendation for Bayesian optimization via Multi-Scale Search<br>
  Tinu Theckel Joy, Santu Rana, Sunil Gupta, Svetha Venkatesh
  [(pdf)](/papers/2016/Theckel.pdf)			
- Safety-Aware Robot Damage Recovery Using Constrained Bayesian Optimization and Simulated Priors<br>
  Vaios Papaspyros, Konstantinos  Chatzilygeroudis, Vassilis Vassiliades, Jean-Baptiste Mouret
  [(pdf)](/papers/2016/Papaspyros.pdf)			
- Learning Optimal Interventions<br>
  Jonas Mueller, David  Reshef, George Du, Tommi Jaakkola
  [(pdf)](/papers/2016/Mueller.pdf)		
- Bayesian Optimisation with Pairwise Preferential Returns<br>
  Javier Gonzalez, Zhenwen Dai, Andreas Damianou, Neil Lawrence
  [(pdf)](/papers/2016/Gonzalez.pdf)			
- Designing Neural Network Hardware Accelerators with Decoupled Objective Evaluations<br>
  Jose Miguel Hernandez-Lobato, Michael A. Gelbart, Brandon Reagen, Robert Adolf, Daniel Hernandez-Lobato, Paul N. Whatmough, David Brooks, Gu-Yeon Wei, Ryan P. Adams
  [(pdf)](/papers/2016/Lobato.pdf)			
- Distributed Thompson Sampling for Large-scale Accelerated Exploration of Chemical Space<br>
  Jose Miguel Hernandez-Lobato, Edward Pyzer-Knapp, Alan Aspuru-Guzik, Ryan Adams
  [(pdf)](/papers/2016/LobatoEdward.pdf)
- Tuning the Scheduling of Distributed Stochastic Gradient Descent with Bayesian Optimization<br>
  Valentin Dalibard, Michael Schaarschmidt, Eiko Yoneki
  [(pdf)](/papers/2016/Dalibard.pdf)
- Do we need “Harmless” Bayesian Optimization and “First-Order” Bayesian Optimization?<br>
  Mohamed Osama Ahmed, Bobak Shahriari, Mark Schmidt
  [(pdf)](/papers/2016/Ahmed.pdf)
- Think Globally, Act Locally: a Local Strategy for Bayesian Optimization<br>
  Vu Nguyen, Sunil Gupta, Santu Rana, Cheng Li, Svetha Venkatesh
  [(pdf)](/papers/2016/Nguyen.pdf)		
- Bayesian Optimization with shape constraints<br>
  Michael Jauch, Victor Pena
  [(pdf)](/papers/2016/Jauch.pdf)			
- Efficient nonmyopic active search<br>
  Shali  Jiang, Gustavo Malkomes, Geoff Converse, Alyssa Shofner, Benjamin Moseley, Roman Garnett
  [(pdf)](/papers/2016/Jiang.pdf)	
